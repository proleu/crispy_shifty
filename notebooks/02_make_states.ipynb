{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make bound and free states from the prepped inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running in directory: /mnt/projects/crispy_shifty/notebooks\n",
      "running on node: dig72\n"
     ]
    }
   ],
   "source": [
    "%load_ext lab_black\n",
    "# Python standard library\n",
    "from glob import glob\n",
    "import os\n",
    "import socket\n",
    "import sys\n",
    "\n",
    "# 3rd party library imports\n",
    "import dask\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pyrosetta\n",
    "import numpy as np\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm  # jupyter compatible progress bar\n",
    "\n",
    "tqdm.pandas()  # link tqdm to pandas\n",
    "# Notebook magic\n",
    "# save plots in the notebook\n",
    "%matplotlib inline\n",
    "# reloads modules automatically before executing cells\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print(f\"running in directory: {os.getcwd()}\")  # where are we?\n",
    "print(f\"running on node: {socket.gethostname()}\")  # what node are we on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set working directory to the root of the crispy_shifty repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/projects/crispy_shifty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a the scorefile containing the cleaned input scaffolds\n",
    "These scaffolds had their disulfides removed and have some standard rosetta metrics, AF2 scores and various metadata written to them.  \n",
    "We will also make the task generator here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/crispy_shifty/envs/crispy/lib/python3.8/site-packages/dask_jobqueue/core.py:20: FutureWarning: tmpfile is deprecated and will be removed in a future release. Please use dask.utils.tmpfile instead.\n",
      "  from distributed.utils import tmpfile\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b60486f046a43648a886dd7185cfcbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sys.path.insert(0, os.getcwd())\n",
    "from crispy_shifty.utils.io import parse_scorefile_linear\n",
    "\n",
    "\n",
    "def create_tasks(scaffolds, options):\n",
    "    for scaffold in scaffolds.index:\n",
    "        # determine where to split the scaffold by counting the number of helixes\n",
    "        num_helices = len(scaffolds.loc[scaffold][\"topo\"])\n",
    "        # split even numbers in half\n",
    "        if num_helices % 2 == 0:\n",
    "            pre_break_helices = [int(num_helices / 2)]\n",
    "        # get middle two for odd numbers\n",
    "        else:\n",
    "            first_helix = int(num_helices / 2)  # rounds down\n",
    "            pre_break_helices = [first_helix, first_helix + 1]\n",
    "        for pre_break_helix in pre_break_helices:\n",
    "            tasks = {}\n",
    "            tasks[\"clash_cutoff\"] = 5000\n",
    "            tasks[\"extra_options\"] = options\n",
    "            # interfaces must be a ratio of 1:3 or 3:1 between the n and c term halves and the bound helix\n",
    "            tasks[\"int_cutoff\"] = 0.33\n",
    "            # get the name of the original design\n",
    "            tasks[\"name\"] = (\n",
    "                scaffolds.loc[scaffold][\"pdb\"].split(\"/\")[-1].replace(\".pdb\", \"\", 1)\n",
    "            )\n",
    "            tasks[\"pdb_path\"] = scaffold\n",
    "            tasks[\"pre_break_helix\"] = pre_break_helix\n",
    "            yield tasks\n",
    "\n",
    "\n",
    "scaffolds = parse_scorefile_linear(\n",
    "    os.path.join(os.getcwd(), \"scaffolds/01_prep_inputs/scores.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Make helix-bound states from the scaffolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run the following from your local terminal to port forward the dashboard to localhost\n",
      "ssh -L 8000:localhost:8787 pleung@dig72\n",
      "dashboard is now visible at localhost:8000\n",
      "can also view dashboard at dig72:8787 without port forwarding\n",
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -e /mnt/projects/crispy_shifty/scaffolds/02_make_bound_states/slurm_logs/dask-worker-%J.err\n",
      "#SBATCH -o /mnt/projects/crispy_shifty/scaffolds/02_make_bound_states/slurm_logs/dask-worker-%J.out\n",
      "#SBATCH -p short\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=1\n",
      "#SBATCH --mem=8G\n",
      "#SBATCH -t 3:00:00\n",
      "\n",
      "/projects/crispy_shifty/envs/crispy/bin/python -m distributed.cli.dask_worker tcp://172.16.131.102:41635 --nthreads 1 --memory-limit 7.45GiB --name dummy-name --nanny --death-timeout 120 --local-directory $TMPDIR --lifetime 3h --lifetime-stagger 5m --protocol tcp://\n",
      "\n",
      "<Client: 'tcp://172.16.131.102:41635' processes=0 threads=0, memory=0 B>\n",
      "distributed run complete\n"
     ]
    }
   ],
   "source": [
    "# Python standard library\n",
    "import os\n",
    "import pwd\n",
    "import socket\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# 3rd party library imports\n",
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "# Rosetta library imports\n",
    "from pyrosetta.distributed.cluster.core import PyRosettaCluster\n",
    "\n",
    "# Custom library imports\n",
    "sys.path.insert(0, os.getcwd())\n",
    "from crispy_shifty.protocols.states import (\n",
    "    make_bound_states,\n",
    ")  # the functions we will distribute\n",
    "\n",
    "\n",
    "print(\n",
    "    \"run the following from your local terminal to port forward the dashboard to localhost\"\n",
    ")\n",
    "print(\n",
    "    f\"ssh -L 8000:localhost:8787 {pwd.getpwuid(os.getuid()).pw_name}@{socket.gethostname()}\"\n",
    ")\n",
    "print(\"dashboard is now visible at localhost:8000\")\n",
    "print(f\"can also view dashboard at {socket.gethostname()}:8787 without port forwarding\")\n",
    "options = {\n",
    "    \"-out:level\": \"200\",  # warning outputs only\n",
    "}\n",
    "output_path = os.path.join(os.getcwd(), \"scaffolds/02_make_bound_states\")\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "logs_path = os.path.join(output_path, \"slurm_logs\")\n",
    "os.makedirs(logs_path, exist_ok=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # configure SLURM cluster as a context manager\n",
    "    with SLURMCluster(\n",
    "        cores=1,\n",
    "        processes=1,\n",
    "        job_cpu=1,\n",
    "        memory=\"8GB\",\n",
    "        queue=\"short\",\n",
    "        walltime=\"3:00:00\",\n",
    "        death_timeout=120,\n",
    "        local_directory=\"$TMPDIR\",  # spill worker litter on local node temp storage\n",
    "        log_directory=logs_path,\n",
    "        extra=[\"--lifetime\", \"3h\", \"--lifetime-stagger\", \"5m\"],\n",
    "    ) as cluster:\n",
    "        print(cluster.job_script())\n",
    "        # scale between 1-150 workers,\n",
    "        cluster.adapt(\n",
    "            minimum=1,\n",
    "            maximum=150,\n",
    "            wait_count=999,  # Number of consecutive times that a worker should be suggested for removal it is removed\n",
    "            interval=\"5s\",  # Time between checks\n",
    "            target_duration=\"60s\",\n",
    "        )\n",
    "        # setup a client to interact with the cluster as a context manager\n",
    "        with Client(cluster) as client:\n",
    "            print(client)\n",
    "            client.upload_file(\n",
    "                os.path.join(os.getcwd(), \"crispy_shifty/protocols/states.py\")\n",
    "            )  # upload the script that contains the functions to distribute\n",
    "            PyRosettaCluster(\n",
    "                client=client,\n",
    "                logging_level=\"WARNING\",\n",
    "                output_path=output_path,\n",
    "                project_name=\"crispy_shifty\",\n",
    "                scratch_dir=output_path,\n",
    "                simulation_name=\"notebooks_02_make_bound_states\",\n",
    "                tasks=create_tasks(scaffolds, options),\n",
    "            ).distribute(protocols=[make_bound_states])\n",
    "            time.sleep(5)\n",
    "            client.close()\n",
    "        time.sleep(5)\n",
    "        cluster.scale(0)\n",
    "        time.sleep(5)\n",
    "        cluster.close()\n",
    "    print(\"distributed run complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make free states from the scaffolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run the following from your local terminal to port forward the dashboard to localhost\n",
      "ssh -L 8000:localhost:8787 pleung@dig72\n",
      "dashboard is now visible at localhost:8000\n",
      "can also view dashboard at dig72:8787 without port forwarding\n",
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -e /mnt/projects/crispy_shifty/scaffolds/02_make_free_states/slurm_logs/dask-worker-%J.err\n",
      "#SBATCH -o /mnt/projects/crispy_shifty/scaffolds/02_make_free_states/slurm_logs/dask-worker-%J.out\n",
      "#SBATCH -p short\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=1\n",
      "#SBATCH --mem=8G\n",
      "#SBATCH -t 3:00:00\n",
      "\n",
      "/projects/crispy_shifty/envs/crispy/bin/python -m distributed.cli.dask_worker tcp://172.16.131.102:34673 --nthreads 1 --memory-limit 7.45GiB --name dummy-name --nanny --death-timeout 120 --local-directory $TMPDIR --lifetime 3h --lifetime-stagger 5m --protocol tcp://\n",
      "\n",
      "<Client: 'tcp://172.16.131.102:34673' processes=0 threads=0, memory=0 B>\n",
      "distributed run complete\n"
     ]
    }
   ],
   "source": [
    "# Python standard library\n",
    "import os\n",
    "import pwd\n",
    "import socket\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# 3rd party library imports\n",
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "# Rosetta library imports\n",
    "from pyrosetta.distributed.cluster.core import PyRosettaCluster\n",
    "\n",
    "# Custom library imports\n",
    "sys.path.insert(0, os.getcwd())\n",
    "from crispy_shifty.protocols.states import (\n",
    "    make_free_states,\n",
    ")  # the functions we will distribute\n",
    "\n",
    "\n",
    "print(\n",
    "    \"run the following from your local terminal to port forward the dashboard to localhost\"\n",
    ")\n",
    "print(\n",
    "    f\"ssh -L 8000:localhost:8787 {pwd.getpwuid(os.getuid()).pw_name}@{socket.gethostname()}\"\n",
    ")\n",
    "print(\"dashboard is now visible at localhost:8000\")\n",
    "print(f\"can also view dashboard at {socket.gethostname()}:8787 without port forwarding\")\n",
    "options = {\n",
    "    \"-out:level\": \"200\",  # warning outputs only\n",
    "}\n",
    "output_path = os.path.join(os.getcwd(), \"scaffolds/02_make_free_states\")\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "logs_path = os.path.join(output_path, \"slurm_logs\")\n",
    "os.makedirs(logs_path, exist_ok=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # configure SLURM cluster as a context manager\n",
    "    with SLURMCluster(\n",
    "        cores=1,\n",
    "        processes=1,\n",
    "        job_cpu=1,\n",
    "        memory=\"8GB\",\n",
    "        queue=\"short\",\n",
    "        walltime=\"3:00:00\",\n",
    "        death_timeout=120,\n",
    "        local_directory=\"$TMPDIR\",  # spill worker litter on local node temp storage\n",
    "        log_directory=logs_path,\n",
    "        extra=[\"--lifetime\", \"3h\", \"--lifetime-stagger\", \"5m\"],\n",
    "    ) as cluster:\n",
    "        print(cluster.job_script())\n",
    "        # scale between 1-150 workers,\n",
    "        cluster.adapt(\n",
    "            minimum=1,\n",
    "            maximum=150,\n",
    "            wait_count=999,  # Number of consecutive times that a worker should be suggested for removal it is removed\n",
    "            interval=\"5s\",  # Time between checks\n",
    "            target_duration=\"60s\",\n",
    "        )\n",
    "        # setup a client to interact with the cluster as a context manager\n",
    "        with Client(cluster) as client:\n",
    "            print(client)\n",
    "            client.upload_file(\n",
    "                os.path.join(os.getcwd(), \"crispy_shifty/protocols/states.py\")\n",
    "            )  # upload the script that contains the functions to distribute\n",
    "            PyRosettaCluster(\n",
    "                client=client,\n",
    "                logging_level=\"WARNING\",\n",
    "                output_path=output_path,\n",
    "                project_name=\"crispy_shifty\",\n",
    "                scratch_dir=output_path,\n",
    "                simulation_name=\"notebooks_02_make_free_states\",\n",
    "                tasks=create_tasks(scaffolds, options),\n",
    "            ).distribute(protocols=[make_free_states])\n",
    "            time.sleep(5)\n",
    "            client.close()\n",
    "        time.sleep(5)\n",
    "        cluster.scale(0)\n",
    "        time.sleep(5)\n",
    "        cluster.close()\n",
    "    print(\"distributed run complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load resulting scorefiles of bound and free states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eccff53f06504ff2a5d0a7c733d37d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2591 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e936da2921c04abfa790e3ea0f982fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3082 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sys.path.insert(0, os.getcwd())\n",
    "from crispy_shifty.utils.io import parse_scorefile_linear\n",
    "\n",
    "bound_scores_df = parse_scorefile_linear(\n",
    "    os.path.join(os.getcwd(), \"scaffolds/02_make_bound_states/scores.json\")\n",
    ")\n",
    "\n",
    "free_scores_df = parse_scorefile_linear(\n",
    "    os.path.join(os.getcwd(), \"scaffolds/02_make_free_states/scores.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save a list of outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0de69b96004126827e5112fb27e159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2591 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0944113d1925405e8cdcc0e65e4488ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3082 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\n",
    "    os.path.join(os.getcwd(), \"scaffolds/02_make_bound_states/bound_states.list\"), \"w\"\n",
    ") as f:\n",
    "    for path in tqdm(bound_scores_df.index):\n",
    "        print(path, file=f)\n",
    "with open(\n",
    "    os.path.join(os.getcwd(), \"scaffolds/02_make_free_states/free_states.list\"), \"w\"\n",
    ") as f:\n",
    "    for path in tqdm(free_scores_df.index):\n",
    "        print(path, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save also a CSV of just free states that have 0 shift\n",
    "We will need them later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_path = os.path.join(\n",
    "    os.getcwd(), \"scaffolds/02_make_free_states/free_state_0s.csv\"\n",
    ")\n",
    "free_state_0s = free_scores_df.query(\"shift == '0' and pivot_helix == pre_break_helix\")\n",
    "free_state_0s.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototyping blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test `make_bound_states`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "import pyrosetta\n",
    "\n",
    "pyrosetta.init()\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"/projects/crispy_shifty/\")\n",
    "from crispy_shifty.protocols.states import make_bound_states\n",
    "# from crispy_shifty.protocols.states import make_bound_states\n",
    "\n",
    "\n",
    "t = make_bound_states(\n",
    "        None,\n",
    "        **{\n",
    "            'pdb_path': '/mnt/projects/crispy_shifty/scaffolds/01_prep_inputs/decoys/0000/notebooks_01_prep_inputs_fa1b5ca9cef5486383f1054118203438.pdb.bz2',\n",
    "            'name': 'DHR78_DHR71_l2_0_v2c',\n",
    "            'pre_break_helix': 2,\n",
    "#             'clash_cutoff': 5000,\n",
    "#             'int_cutoff': 0.9,\n",
    "#             'full_helix': True,\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, tppose in enumerate(t):\n",
    "    tppose.pose.dump_pdb(f\"{tppose.scores['state']}.pdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test `grow_terminal_helices`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyrosetta\n",
    "\n",
    "sys.path.insert(0, \"/projects/crispy_shifty/\")\n",
    "from crispy_shifty.protocols.states import grow_terminal_helices\n",
    "\n",
    "\n",
    "pyrosetta.init()\n",
    "tpose = pyrosetta.pose_from_file(\n",
    "    \"/home/pleung/projects/bistable_bundle/r4/helix_binders/08_analysis/pdbs/cs_088_Y.pdb\"\n",
    ")\n",
    "tpose2 = grow_terminal_helices(\n",
    "    pose=tpose,\n",
    "    chain=2,\n",
    "    extend_n_term=7,\n",
    "    extend_c_term=7,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test `extend_helix_termini`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyrosetta\n",
    "\n",
    "sys.path.insert(0, \"/projects/crispy_shifty/\")\n",
    "from crispy_shifty.protocols.states import extend_helix_termini\n",
    "\n",
    "\n",
    "pyrosetta.init()\n",
    "tpose = pyrosetta.pose_from_file(\n",
    "    \"/home/pleung/projects/bistable_bundle/r4/helix_binders/08_analysis/pdbs/cs_088_Y.pdb\"\n",
    ")\n",
    "tpose2 = extend_helix_termini(\n",
    "    pose=tpose,\n",
    "    chain=2,\n",
    "    extend_n_term=7,\n",
    "    extend_c_term=7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpose2.dump_pdb(\"test2.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crispy (3.8.12)",
   "language": "python",
   "name": "crispy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
