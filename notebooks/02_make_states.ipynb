{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make bound and free states from the prepped inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running in directory: /mnt/home/pleung/projects/crispy_shifty/notebooks\n",
      "running on node: dig42\n"
     ]
    }
   ],
   "source": [
    "%load_ext lab_black\n",
    "# Python standard library\n",
    "from glob import glob\n",
    "import os\n",
    "import socket\n",
    "import sys\n",
    "\n",
    "# 3rd party library imports\n",
    "import dask\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pyrosetta\n",
    "import numpy as np\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm  # jupyter compatible progress bar\n",
    "\n",
    "tqdm.pandas()  # link tqdm to pandas\n",
    "# Notebook magic\n",
    "# save plots in the notebook\n",
    "%matplotlib inline\n",
    "# reloads modules automatically before executing cells\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print(f\"running in directory: {os.getcwd()}\")  # where are we?\n",
    "print(f\"running on node: {socket.gethostname()}\")  # what node are we on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set working directory to the root of the crispy_shifty repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/pleung/projects/crispy_shifty\")  # TODO projects dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a the scorefile containing the cleaned input scaffolds\n",
    "These scaffolds had their disulfides removed and have some standard rosetta metrics, AF2 scores and various metadata written to them.  \n",
    "We will also make the task generator here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.getcwd())\n",
    "from crispy_shifty.utils.io import parse_scorefile_linear\n",
    "\n",
    "\n",
    "def create_tasks(scaffolds, options):\n",
    "    for scaffold in scaffolds.index:\n",
    "        # determine where to split the scaffold by counting the number of helixes    \n",
    "        num_helices = len(scaffolds.loc[scaffold][\"topo\"])\n",
    "        # split even numbers in half\n",
    "        if num_helices % 2 == 0:\n",
    "            pre_break_helices = [int(num_helices / 2)]\n",
    "        # get middle two for odd numbers\n",
    "        else:\n",
    "            first_helix = int(num_helices / 2)  # rounds down\n",
    "            pre_break_helices = [first_helix, first_helix + 1]\n",
    "        for pre_break_helix in pre_break_helices:\n",
    "            tasks = {}\n",
    "            tasks[\"clash_cutoff\"] = 5000\n",
    "            tasks[\"extra_options\"] = options\n",
    "            # interfaces must be a ratio of 1:3 or 3:1 between the n and c term halves and the bound helix\n",
    "            tasks[\"int_cutoff\"] = 0.33\n",
    "            # get the name of the original design\n",
    "            tasks[\"name\"] = (\n",
    "                scaffolds.loc[scaffold][\"pdb\"].split(\"/\")[-1].replace(\".pdb\", \"\", 1)\n",
    "            )\n",
    "            tasks[\"pdb_path\"] = scaffold\n",
    "            tasks[\"pre_break_helix\"] = pre_break_helix\n",
    "            yield tasks\n",
    "\n",
    "\n",
    "scaffolds = parse_scorefile_linear(\n",
    "    os.path.join(os.getcwd(), \"scaffolds/01_prep_inputs/scores.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make helix-bound states from the scaffolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Use of `pyrosetta.distributed.cluster` namespace requires Anaconda (or Miniconda) to be properly installed for reproducibility of PyRosetta simulations. Please install Anaconda (or Miniconda) onto your system to enable running `which conda`. For installation instructions, visit:\n",
      "https://docs.anaconda.com/anaconda/install\n",
      "\n",
      "run the following from your local terminal to port forward the dashboard to localhost\n",
      "ssh -L 8000:localhost:8787 pleung@dig71\n",
      "dashboard is now visible at localhost:8000\n",
      "can also view dashboard at dig71:8787 without port forwarding\n",
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -e /mnt/home/pleung/logs/slurm_logs/dask-worker-%J.err\n",
      "#SBATCH -o /mnt/home/pleung/logs/slurm_logs/dask-worker-%J.out\n",
      "#SBATCH -p short\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=1\n",
      "#SBATCH --mem=8G\n",
      "#SBATCH -t 3:00:00\n",
      "\n",
      "/home/pleung/.conda/envs/crispy/bin/python -m distributed.cli.dask_worker tcp://172.16.131.101:43227 --nthreads 1 --memory-limit 7.45GiB --name dummy-name --nanny --death-timeout 120 --local-directory $TMPDIR --lifetime 3h --lifetime-stagger 5m --protocol tcp://\n",
      "\n",
      "<Client: 'tcp://172.16.131.101:43227' processes=0 threads=0, memory=0 B>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:`conda env export --prefix /home/pleung/.conda/envs/crispy` did not run successfully, so the active conda environment YML file string was not saved! It is recommended to run: \n",
      "`conda env export --prefix /home/pleung/.conda/envs/crispy > environment.yml`\n",
      "to reproduce this simulation later.\n"
     ]
    }
   ],
   "source": [
    "# Python standard library\n",
    "import os\n",
    "import pwd\n",
    "import socket\n",
    "import sys\n",
    "\n",
    "# 3rd party library imports\n",
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "# Rosetta library imports\n",
    "from pyrosetta.distributed.cluster.core import PyRosettaCluster\n",
    "\n",
    "# Custom library imports\n",
    "sys.path.insert(0, os.getcwd())\n",
    "from crispy_shifty.protocols.states import make_bound_states  # the functions we will distribute\n",
    "\n",
    "\n",
    "print(\n",
    "    \"run the following from your local terminal to port forward the dashboard to localhost\"\n",
    ")\n",
    "print(\n",
    "    f\"ssh -L 8000:localhost:8787 {pwd.getpwuid(os.getuid()).pw_name}@{socket.gethostname()}\"\n",
    ")\n",
    "print(\"dashboard is now visible at localhost:8000\")\n",
    "print(f\"can also view dashboard at {socket.gethostname()}:8787 without port forwarding\")\n",
    "options = {\n",
    "    \"-out:level\": \"200\",  # warning outputs only\n",
    "}\n",
    "output_path = os.path.join(os.getcwd(), \"scaffolds/02_make_states\")\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # configure SLURM cluster as a context manager\n",
    "    with SLURMCluster(\n",
    "        cores=1,\n",
    "        processes=1,\n",
    "        job_cpu=1,\n",
    "        memory=\"8GB\",\n",
    "        queue=\"short\",\n",
    "        walltime=\"3:00:00\",\n",
    "        death_timeout=120,\n",
    "        local_directory=\"$TMPDIR\",  # spill worker litter on local node temp storage\n",
    "        log_directory=\"/mnt/home/pleung/logs/slurm_logs\",\n",
    "        extra=[\"--lifetime\", \"3h\", \"--lifetime-stagger\", \"5m\"],\n",
    "    ) as cluster:\n",
    "        print(cluster.job_script())\n",
    "        # scale between 1-150 workers,\n",
    "        cluster.adapt(\n",
    "            minimum=1,\n",
    "            maximum=150,\n",
    "            wait_count=999,  # Number of consecutive times that a worker should be suggested for removal it is removed\n",
    "            interval=\"5s\",  # Time between checks\n",
    "            target_duration=\"60s\",\n",
    "        )\n",
    "        # setup a client to interact with the cluster as a context manager\n",
    "        with Client(cluster) as client:\n",
    "            print(client)\n",
    "            client.upload_file(\n",
    "                os.path.join(os.getcwd(), \"crispy_shifty/protocols/states.py\")\n",
    "            )  # upload the script that contains the functions to distribute\n",
    "            PyRosettaCluster(\n",
    "                client=client,\n",
    "                logging_level=\"WARNING\",\n",
    "                output_path=output_path,\n",
    "                project_name=\"crispy_shifty\",\n",
    "                scratch_dir=output_path,\n",
    "                simulation_name=\"notebooks_02_make_states\",\n",
    "                tasks=create_tasks(scaffolds, options),\n",
    "            ).distribute(protocols=[make_bound_states])\n",
    "            client.close()\n",
    "        cluster.scale(0)\n",
    "        cluster.close()\n",
    "    print(\"distributed run complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unused blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyRosetta-4 2021 [Rosetta PyRosetta4.conda.linux.cxx11thread.serialization.CentOS.python38.Release 2021.31+release.c7009b3115c22daa9efe2805d9d1ebba08426a54 2021-08-07T10:04:12] retrieved from: http://www.pyrosetta.org\n",
      "(C) Copyright Rosetta Commons Member Institutions. Created in JHU by Sergey Lyskov and PyRosetta Team.\n",
      "core.init: {0} Checking for fconfig files in pwd and ./rosetta/flags\n",
      "core.init: {0} Rosetta version: PyRosetta4.conda.linux.cxx11thread.serialization.CentOS.python38.Release r292 2021.31+release.c7009b3 c7009b3115c22daa9efe2805d9d1ebba08426a54 http://www.pyrosetta.org 2021-08-07T10:04:12\n",
      "core.init: {0} command: PyRosetta -ex1 -ex2aro -database /home/pleung/.conda/envs/crispy/lib/python3.8/site-packages/pyrosetta/database\n",
      "basic.random.init_random_generator: {0} 'RNG device' seed mode, using '/dev/urandom', seed=-1505151078 seed_offset=0 real_seed=-1505151078 thread_index=0\n",
      "basic.random.init_random_generator: {0} RandomGenerator:init: Normal mode, seed=-1505151078 RG_type=mt19937\n",
      "CPU times: user 34.3 ms, sys: 3.92 ms, total: 38.2 ms\n",
      "Wall time: 45.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import pyrosetta\n",
    "\n",
    "pyrosetta.init()\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"~/projects/crispy_shifty/\") # TODO projects\n",
    "from crispy_shifty.protocols.states import make_bound_states\n",
    "\n",
    "\n",
    "t = make_bound_states(\n",
    "        None,\n",
    "        **{\n",
    "            'pdb_path': '/mnt/projects/crispy_shifty/scaffolds/01_prep_inputs/decoys/0007/notebooks_01_prep_inputs_e415bdb161304f5bacaafab4572b14aa.pdb.bz2',\n",
    "            'name': 'DHR77_DHR5_l2_t2_t1_1_v4c',\n",
    "            'pre_break_helix': 4,\n",
    "            'clash_cutoff': 5000,\n",
    "            'int_cutoff': 0.33,\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crispy (3.8.10)",
   "language": "python",
   "name": "crispy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
