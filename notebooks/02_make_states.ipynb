{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make bound and free states from the prepped inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running in directory: /mnt/home/pleung/projects/crispy_shifty/notebooks\n",
      "running on node: dig38\n"
     ]
    }
   ],
   "source": [
    "%load_ext lab_black\n",
    "# Python standard library\n",
    "from glob import glob\n",
    "import os\n",
    "import socket\n",
    "import sys\n",
    "\n",
    "# 3rd party library imports\n",
    "import dask\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pyrosetta\n",
    "import numpy as np\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm  # jupyter compatible progress bar\n",
    "\n",
    "tqdm.pandas()  # link tqdm to pandas\n",
    "# Notebook magic\n",
    "# save plots in the notebook\n",
    "%matplotlib inline\n",
    "# reloads modules automatically before executing cells\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print(f\"running in directory: {os.getcwd()}\")  # where are we?\n",
    "print(f\"running on node: {socket.gethostname()}\")  # what node are we on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set working directory to the root of the crispy_shifty repo\n",
    "TODO set to projects dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/pleung/projects/crispy_shifty\")\n",
    "# os.chdir(\"/projects/crispy_shifty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a the scorefile containing the cleaned input scaffolds\n",
    "These scaffolds had their disulfides removed and have some standard rosetta metrics, AF2 scores and various metadata written to them.  \n",
    "We will also make the task generator here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee568da1573f45148da82311af622679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sys.path.insert(0, os.getcwd())\n",
    "from crispy_shifty.utils.io import parse_scorefile_linear\n",
    "\n",
    "\n",
    "def create_tasks(scaffolds, options):\n",
    "    for scaffold in scaffolds.index:\n",
    "        # determine where to split the scaffold by counting the number of helixes\n",
    "        num_helices = len(scaffolds.loc[scaffold][\"topo\"])\n",
    "        # split even numbers in half\n",
    "        if num_helices % 2 == 0:\n",
    "            pre_break_helices = [int(num_helices / 2)]\n",
    "        # get middle two for odd numbers\n",
    "        else:\n",
    "            first_helix = int(num_helices / 2)  # rounds down\n",
    "            pre_break_helices = [first_helix, first_helix + 1]\n",
    "        for pre_break_helix in pre_break_helices:\n",
    "            tasks = {}\n",
    "            tasks[\"clash_cutoff\"] = 5000\n",
    "            tasks[\"extra_options\"] = options\n",
    "            # interfaces must be a ratio of 1:3 or 3:1 between the n and c term halves and the bound helix\n",
    "            tasks[\"int_cutoff\"] = 0.33\n",
    "            # get the name of the original design\n",
    "            tasks[\"name\"] = (\n",
    "                scaffolds.loc[scaffold][\"pdb\"].split(\"/\")[-1].replace(\".pdb\", \"\", 1)\n",
    "            )\n",
    "            tasks[\"pdb_path\"] = scaffold\n",
    "            tasks[\"pre_break_helix\"] = pre_break_helix\n",
    "            yield tasks\n",
    "\n",
    "\n",
    "scaffolds = parse_scorefile_linear(\n",
    "    os.path.join(os.getcwd(), \"scaffolds/01_prep_inputs/scores.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make helix-bound states from the scaffolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run the following from your local terminal to port forward the dashboard to localhost\n",
      "ssh -L 8000:localhost:8787 pleung@dig38\n",
      "dashboard is now visible at localhost:8000\n",
      "can also view dashboard at dig38:8787 without port forwarding\n",
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -e /mnt/home/pleung/logs/slurm_logs/dask-worker-%J.err\n",
      "#SBATCH -o /mnt/home/pleung/logs/slurm_logs/dask-worker-%J.out\n",
      "#SBATCH -p short\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=1\n",
      "#SBATCH --mem=8G\n",
      "#SBATCH -t 3:00:00\n",
      "\n",
      "/home/pleung/.conda/envs/crispy/bin/python -m distributed.cli.dask_worker tcp://172.16.131.68:36027 --nthreads 1 --memory-limit 7.45GiB --name dummy-name --nanny --death-timeout 120 --local-directory $TMPDIR --lifetime 3h --lifetime-stagger 5m --protocol tcp://\n",
      "\n",
      "<Client: 'tcp://172.16.131.68:36027' processes=0 threads=0, memory=0 B>\n"
     ]
    },
    {
     "ename": "InvalidGitRepositoryError",
     "evalue": "There are untracked files in your git repository! If these are important for the simulation, you will not be able to reproduce your work! Commit the changes if appropriate, or add untracked files to your .gitignore file before running PyRosettaCluster!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidGitRepositoryError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m/scratch/pleung/66463360/ipykernel_2598657/3220344773.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"crispy_shifty/protocols/states.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             )  # upload the script that contains the functions to distribute\n\u001b[0;32m---> 64\u001b[0;31m             PyRosettaCluster(\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mlogging_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"WARNING\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crispy/lib/python3.8/site-packages/pyrosetta/distributed/cluster/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tasks, nstruct, input_packed_pose, seeds, decoy_ids, client, scheduler, cores, processes, memory, scratch_dir, min_workers, max_workers, dashboard_address, project_name, simulation_name, output_path, scorefile_name, simulation_records_in_scorefile, decoy_dir_name, logs_dir_name, logging_level, compressed, sha1, ignore_errors, timeout, save_all, dry_run, system_info, pyrosetta_build, environment)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__attr_factory_logging_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompressed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__attr_converter_compressed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompressed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msha1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__attr_converter_sha1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msha1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__attr_converter_ignore_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__attr_converter_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crispy/lib/python3.8/site-packages/pyrosetta/distributed/cluster/converters.py\u001b[0m in \u001b[0;36m_parse_sha1\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crispy/lib/python3.8/functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    873\u001b[0m                             '1 positional argument')\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[0mfuncname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'singledispatch function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crispy/lib/python3.8/site-packages/pyrosetta/distributed/cluster/converters.py\u001b[0m in \u001b[0;36m_register_str\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;31m# Ensure that everything in the work directory is included in the repository\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muntracked_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                 raise git.InvalidGitRepositoryError(\n\u001b[0m\u001b[1;32m    267\u001b[0m                     \u001b[0;34m\"There are untracked files in your git repository! \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                     \u001b[0;34m+\u001b[0m \u001b[0;34m\"If these are important for the simulation, you will not \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidGitRepositoryError\u001b[0m: There are untracked files in your git repository! If these are important for the simulation, you will not be able to reproduce your work! Commit the changes if appropriate, or add untracked files to your .gitignore file before running PyRosettaCluster!"
     ]
    }
   ],
   "source": [
    "# Python standard library\n",
    "import os\n",
    "import pwd\n",
    "import socket\n",
    "import sys\n",
    "\n",
    "# 3rd party library imports\n",
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "# Rosetta library imports\n",
    "from pyrosetta.distributed.cluster.core import PyRosettaCluster\n",
    "\n",
    "# Custom library imports\n",
    "sys.path.insert(0, os.getcwd())\n",
    "from crispy_shifty.protocols.states import (\n",
    "    make_bound_states,\n",
    ")  # the functions we will distribute\n",
    "\n",
    "\n",
    "print(\n",
    "    \"run the following from your local terminal to port forward the dashboard to localhost\"\n",
    ")\n",
    "print(\n",
    "    f\"ssh -L 8000:localhost:8787 {pwd.getpwuid(os.getuid()).pw_name}@{socket.gethostname()}\"\n",
    ")\n",
    "print(\"dashboard is now visible at localhost:8000\")\n",
    "print(f\"can also view dashboard at {socket.gethostname()}:8787 without port forwarding\")\n",
    "options = {\n",
    "    \"-out:level\": \"200\",  # warning outputs only\n",
    "}\n",
    "output_path = os.path.join(os.getcwd(), \"scaffolds/02_make_bound_states\")\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # configure SLURM cluster as a context manager\n",
    "    with SLURMCluster(\n",
    "        cores=1,\n",
    "        processes=1,\n",
    "        job_cpu=1,\n",
    "        memory=\"8GB\",\n",
    "        queue=\"short\",\n",
    "        walltime=\"3:00:00\",\n",
    "        death_timeout=120,\n",
    "        local_directory=\"$TMPDIR\",  # spill worker litter on local node temp storage\n",
    "        log_directory=\"/mnt/home/pleung/logs/slurm_logs\",\n",
    "        extra=[\"--lifetime\", \"3h\", \"--lifetime-stagger\", \"5m\"],\n",
    "    ) as cluster:\n",
    "        print(cluster.job_script())\n",
    "        # scale between 1-150 workers,\n",
    "        cluster.adapt(\n",
    "            minimum=1,\n",
    "            maximum=150,\n",
    "            wait_count=999,  # Number of consecutive times that a worker should be suggested for removal it is removed\n",
    "            interval=\"5s\",  # Time between checks\n",
    "            target_duration=\"60s\",\n",
    "        )\n",
    "        # setup a client to interact with the cluster as a context manager\n",
    "        with Client(cluster) as client:\n",
    "            print(client)\n",
    "            client.upload_file(\n",
    "                os.path.join(os.getcwd(), \"crispy_shifty/protocols/states.py\")\n",
    "            )  # upload the script that contains the functions to distribute\n",
    "            PyRosettaCluster(\n",
    "                client=client,\n",
    "                logging_level=\"WARNING\",\n",
    "                output_path=output_path,\n",
    "                project_name=\"crispy_shifty\",\n",
    "                scratch_dir=output_path,\n",
    "                simulation_name=\"notebooks_02_make_bound_states\",\n",
    "                tasks=create_tasks(scaffolds, options),\n",
    "            ).distribute(protocols=[make_bound_states])\n",
    "            client.close()\n",
    "        cluster.scale(0)\n",
    "        cluster.close()\n",
    "    print(\"distributed run complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make free states from the scaffolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python standard library\n",
    "import os\n",
    "import pwd\n",
    "import socket\n",
    "import sys\n",
    "\n",
    "# 3rd party library imports\n",
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "# Rosetta library imports\n",
    "from pyrosetta.distributed.cluster.core import PyRosettaCluster\n",
    "\n",
    "# Custom library imports\n",
    "sys.path.insert(0, os.getcwd())\n",
    "from crispy_shifty.protocols.states import (\n",
    "    make_free_states,\n",
    ")  # the functions we will distribute\n",
    "\n",
    "\n",
    "print(\n",
    "    \"run the following from your local terminal to port forward the dashboard to localhost\"\n",
    ")\n",
    "print(\n",
    "    f\"ssh -L 8000:localhost:8787 {pwd.getpwuid(os.getuid()).pw_name}@{socket.gethostname()}\"\n",
    ")\n",
    "print(\"dashboard is now visible at localhost:8000\")\n",
    "print(f\"can also view dashboard at {socket.gethostname()}:8787 without port forwarding\")\n",
    "options = {\n",
    "    \"-out:level\": \"200\",  # warning outputs only\n",
    "}\n",
    "output_path = os.path.join(os.getcwd(), \"scaffolds/02_make_free_states\")\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # configure SLURM cluster as a context manager\n",
    "    with SLURMCluster(\n",
    "        cores=1,\n",
    "        processes=1,\n",
    "        job_cpu=1,\n",
    "        memory=\"8GB\",\n",
    "        queue=\"short\",\n",
    "        walltime=\"3:00:00\",\n",
    "        death_timeout=120,\n",
    "        local_directory=\"$TMPDIR\",  # spill worker litter on local node temp storage\n",
    "        log_directory=\"/mnt/home/pleung/logs/slurm_logs\",\n",
    "        extra=[\"--lifetime\", \"3h\", \"--lifetime-stagger\", \"5m\"],\n",
    "    ) as cluster:\n",
    "        print(cluster.job_script())\n",
    "        # scale between 1-150 workers,\n",
    "        cluster.adapt(\n",
    "            minimum=1,\n",
    "            maximum=150,\n",
    "            wait_count=999,  # Number of consecutive times that a worker should be suggested for removal it is removed\n",
    "            interval=\"5s\",  # Time between checks\n",
    "            target_duration=\"60s\",\n",
    "        )\n",
    "        # setup a client to interact with the cluster as a context manager\n",
    "        with Client(cluster) as client:\n",
    "            print(client)\n",
    "            client.upload_file(\n",
    "                os.path.join(os.getcwd(), \"crispy_shifty/protocols/states.py\")\n",
    "            )  # upload the script that contains the functions to distribute\n",
    "            PyRosettaCluster(\n",
    "                client=client,\n",
    "                logging_level=\"WARNING\",\n",
    "                output_path=output_path,\n",
    "                project_name=\"crispy_shifty\",\n",
    "                scratch_dir=output_path,\n",
    "                simulation_name=\"notebooks_02_make_free_states\",\n",
    "                tasks=create_tasks(scaffolds, options),\n",
    "            ).distribute(protocols=[make_free_states])\n",
    "            client.close()\n",
    "        cluster.scale(0)\n",
    "        cluster.close()\n",
    "    print(\"distributed run complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load resulting scorefiles of bound and free states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.getcwd())\n",
    "from crispy_shifty.utils.io import parse_scorefile_linear\n",
    "\n",
    "bound_scores_df = parse_scorefile_linear(\n",
    "    os.path.join(os.getcwd(), \"scaffolds/02_make_bound_states/scores.json\")\n",
    ")\n",
    "\n",
    "free_scores_df = parse_scorefile_linear(\n",
    "    os.path.join(os.getcwd(), \"scaffolds/02_make_free_states/scores.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save a list of outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    os.path.join(os.getcwd(), \"scaffolds/02_make_bound_states/bound_states.list\"), \"w\"\n",
    ") as f:\n",
    "    for path in tqdm(bound_scores_df.index):\n",
    "        print(path, file=f)\n",
    "with open(\n",
    "    os.path.join(os.getcwd(), \"scaffolds/02_make_free_states/free_states.list\"), \"w\"\n",
    ") as f:\n",
    "    for path in tqdm(free_scores_df.index):\n",
    "        print(path, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unused blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "import pyrosetta\n",
    "\n",
    "pyrosetta.init()\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"~/projects/crispy_shifty/\") # TODO projects\n",
    "from crispy_shifty.protocols.oop_states import make_bound_states\n",
    "# from crispy_shifty.protocols.states import make_bound_states\n",
    "\n",
    "\n",
    "t = make_bound_states(\n",
    "        None,\n",
    "        **{\n",
    "            'pdb_path': '/projects/crispy_shifty/scaffolds/01_prep_inputs/decoys/0007/notebooks_01_prep_inputs_ed174efba2714e1aaaa163c9fc406d39.pdb.bz2',\n",
    "            'name': 'DHR78_DHR71_l2_0_v2c',\n",
    "            'pre_break_helix': 4,\n",
    "#             'clash_cutoff': 5000,\n",
    "#             'int_cutoff': 0.9,\n",
    "#             'full_helix': True,\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, tppose in enumerate(t):\n",
    "    tppose.pose.dump_pdb(f\"{tppose.scores['state']}.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crispy (3.8.10)",
   "language": "python",
   "name": "crispy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
