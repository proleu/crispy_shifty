# Python standard library
from operator import eq, ge, gt, le, lt, ne
from typing import Any, Dict, Iterator, List, Optional, Tuple, Union

# 3rd party library imports
# Rosetta library imports
from pyrosetta.distributed.packed_pose.core import PackedPose
from pyrosetta.distributed import requires_init
from pyrosetta.rosetta.core.pose import Pose
from pyrosetta.rosetta.core.select.residue_selector import ResidueSelector

# Custom library imports

af2_metrics = [
    "mean_pae",
    "mean_pae_interaction",
    "mean_pae_interaction_AB",
    "mean_pae_interaction_BA",
    "mean_pae_intra_chain",
    "mean_pae_intra_chain_A",
    "mean_pae_intra_chain_B",
    "mean_plddt",
    "model",
    "pTMscore",
    "recycles",
    "rmsd_to_input",
    "rmsd_to_reference",
    "seed",
    "tol",
    "type",
]


def generate_decoys_from_pose(
    pose: Pose,
    filter_dict: Dict[
        str, Tuple[Union[eq, ge, gt, le, lt, ne], Union[int, float, str]]
    ] = {},
    generate_prediction_decoys: Optional[bool] = False,
    label_first: Optional[bool] = False,
    prefix: Optional[str] = "tmp",
    rank_on: Optional[
        Union[str, bool] # "mean_plddt", "pTMscore", "rmsd_to_input", "rmsd_to_reference", or False
    ] = "mean_plddt",
    **kwargs,
) -> Iterator[Pose]:
    """
    :param: pose: Pose object to generate decoys from.
    :param: filter_dict: dictionary of filters to apply to the decoys. This is supplied
    as a dictionary of the form {'score_name': (operator, value)} where the operator is
    one of the following: eq, ge, gt, le, lt, ne. Example: {'mean_plddt': (ge, 0.9)} .
    Note that this defaults to an empty dict, which will simply return all decoys.
    :param: generate_prediction_decoys: If True, generate decoys for the predictions
    instead of threading the sequences onto the input pose.
    :param: label_first: If True, label the first decoy as designed by rosetta and the
    rest as designed by mpnn.
    prefix: for poses with many tags/pymol_names in results, get all results with the
    same prefix
    rank_on: the score to rank multiple model results for the same tag/pymol_name on.
    kwargs: keyword arguments (if they are not in the named arguments they will be ignored)
    :return: iterator of poses
    The decoys are generated by applying the filters to the model results in the pose.
    """
    import json, sys
    from pathlib import Path
    import pyrosetta
    import pyrosetta.distributed.io as io
    from pyrosetta.rosetta.core.pose import setPoseExtraScore

    sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
    from crispy_shifty.protocols.mpnn import thread_full_sequence

    # get the scores from the pose that have the prefix
    scores = {k: v for k, v in pose.scores.items() if prefix in k}
    # get the scores from the pose that don't have the prefix
    pose_scores = {k: v for k, v in pose.scores.items() if prefix not in k}
    # the format we expect is
    # {'tag1': {'model_seed': json_string of scores dict, 'seq': sequence}, tag2: ...}
    # for each tag, check that the format is correct then:
    # 1. get the sequence
    # 2. get the (possibly multiple) model/seed results by loading the json_string
    # 3. sort the model/seed results by the rank_on score and take the top result only
    # 4. apply the filter(s) that result
    for i, (tag, result) in enumerate(sorted(scores.items())):
        # try to load the json string
        try:
            results = json.loads(result)
        # fail gracefully if it can't be loaded
        except json.decoder.JSONDecodeError:
            print(f"Could not load json string for {tag}")
            continue
        # anything that doesn't have a seq or results is a problem, once loaded
        if "seq" not in results.keys():
            raise ValueError(
                f"{tag} does not have a sequence in the pose datacache. "
                "This is required for generating decoys."
            )
        else:
            sequence = results.pop("seq")
        # remaining should be model/seed results
        if "model_" not in list(results.keys())[0]:
            raise ValueError(
                f"{tag} does not have a model/seed in the pose datacache. "
                "This is required for generating decoys."
            )
        else:
            pass
        if rank_on is False:
            # return all the decoys
            top_results = [x[1] for x in results.items()]
        else:
            # sort the model/seed results by the rank_on score and take the top result only
            # this is a bit tricky because higher is better for mean_plddt and pTMscore
            # and lower is better for rmsd_to_input and rmsd_to_reference
            if rank_on == "mean_plddt" or rank_on == "pTMscore":
                # higher is better
                model_seed_results = sorted(
                    results.items(), key=lambda x: x[1][rank_on], reverse=True
                )
            elif rank_on == "rmsd_to_input" or rank_on == "rmsd_to_reference":
                # lower is better
                model_seed_results = sorted(
                    results.items(), key=lambda x: x[1][rank_on], reverse=False
                )
            else:
                raise ValueError(
                    f"{rank_on} is not a valid rank_on score. "
                    "This is required for generating decoys."
                )
            # get the top result
            top_results = [model_seed_results[0][1]]
        for top_result in top_results:
            # setup flag: the decoy hasn't been discarded yet
            keep_decoy = True
            # apply the filter(s)
            for score_name, (operator, value) in filter_dict.items():
                if operator(top_result[score_name], value):
                    pass
                else:
                    # if the filter fails, don't keep the decoy
                    keep_decoy = False
                    break
            # if the decoy passes all filters, yield it
            if keep_decoy:
                if generate_prediction_decoys:
                    decoy_pdbstring = top_result.pop("decoy_pdbstring")
                    decoy = io.to_pose(io.pose_from_pdbstring(decoy_pdbstring))
                else:
                    decoy = thread_full_sequence(
                        pose,
                        sequence,
                    )
                # add the scores from the top result to the decoy
                pose_scores.update(top_result)
                if label_first:
                    if tag == "mpnn_seq_0000":
                        pose_scores["designed_by"] = "rosetta"
                    else:
                        pose_scores["designed_by"] = "mpnn"
                else:
                    pass
                # clear decoy scores
                pyrosetta.rosetta.core.pose.clearPoseExtraScores(decoy)
                for k, v in pose_scores.items():
                    setPoseExtraScore(decoy, k, v)
                yield decoy
            else:
                pass
    return


def process_results_json(path: str) -> Tuple[str, str, Dict[Any, Any]]:
    """
    :param: path: The path to the JSON to process.
    :return: A tuple containing the name/tag of the prediction target, the name of the
    model/seed that generated the results and the dictionary of results.
    Load a JSON as a dict. Return the name of the prediction target, the name of the
    model/seed that generated the results and the dictionary of results.
    """
    import json

    with open(path, "r") as f:
        scores = json.load(f)

    model = scores["model"]
    seed = scores["seed"]
    if "ptm" in scores["type"]:
        ptm = "_ptm"
    else:
        ptm = ""
    # results json filenames have the format:
    # {pymol_name}_model_{model}{""|"ptm"}_seed_{seed}_prediction_results.json
    # if we work backwards, after loading the json, we can get the pymol_name
    filename = path.split("/")[-1]
    model_seed = f"model_{model}{ptm}_seed_{seed}"
    pymol_name = filename.replace(f"_{model_seed}_prediction_results.json", "")
    return pymol_name, model_seed, scores


class SuperfoldRunner:
    """
    Class for running AF2 on any cluster with @rdkibler's Superfold.
    """

    import os, pwd, uuid, shutil
    import pyrosetta.distributed.io as io

    def __init__(
        self,
        pose: Union[Pose, PackedPose],
        input_file: Optional[str] = None,
        amber_relax: bool = False,
        fasta_path: Optional[str] = None,
        initial_guess: Optional[Union[bool, str]] = None,
        load_decoys: Optional[bool] = False,
        max_recycles: Optional[int] = 3,
        model_type: Optional[str] = "monomer_ptm",
        models: Optional[Union[int, List[int], List[str], str]] = "all",
        recycle_tol: Optional[float] = 0.0,
        reference_pdb: Optional[str] = None,
        simple_rmsd: Optional[bool] = True,
        **kwargs,
    ):
        """
        :param: pose: The pose to run Superfold on.
        :param: input_file: The path to the input file. If none, the pose will be used
        on its own.
        :param: amber_relax: Whether to run AMBER relaxation.
        :param: fasta_path: The path to the FASTA file, if any.
        :param: initial_guess: Whether to use an initial guess. If True, the pose will
        be used as an initial guess. If a string, the string will be used as the path
        to the initial guess.
        :param: load_decoys: Whether to load decoy PDBs from the results.
        :param: max_recycles: The maximum number of cycles to run Superfold.
        :param: model_type: The type of model to run.
        :param: models: The models to run.
        :param: recycle_tol: The tolerance for recycling. If the difference between
        mean plddt changes less than this value since the last recycle, the model will
        stop early.
        :param: reference_pdb: The path to the reference PDB for RMSD calculation.
        Initialize the class with the provided attributes.
        """

        import git
        import os
        from pathlib import Path

        self.pose = pose
        self.input_file = input_file
        self.amber_relax = amber_relax
        self.fasta_path = fasta_path
        self.initial_guess = initial_guess
        self.load_decoys = load_decoys
        self.max_recycles = max_recycles
        self.model_type = model_type
        self.models = models
        self.recycle_tol = recycle_tol
        self.simple_rmsd = simple_rmsd
        self.reference_pdb = reference_pdb
        # setup standard flags for superfold
        self.flags = {
            "--mock_msa_depth": "1",
            "--nstruct": "1",
            "--num_ensemble": "1",
            "--pct_seq_mask": "0.15",
            "--seed_start": "0",
            "--version": "monomer",
        }
        # add the flags provided by the user
        # the initial_guess flag is a special case because it is a boolean or string
        initial_guess_flag = "--initial_guess"
        if self.initial_guess is not None:
            if initial_guess == True:
                self.flags[initial_guess_flag] = " "
            else:
                self.flags[initial_guess_flag] = self.initial_guess
        else:
            pass
        # the amber_relax and reference_pdb flags are special cases as well
        if self.amber_relax:
            # store_true flag
            self.flags["--amber_relax"] = " "
        else:
            pass
        if self.simple_rmsd:
            # store_true flag
            self.flags["--simple_rmsd"] = " "
        else:
            pass
        if self.reference_pdb is not None:
            self.flags["--reference_pdb"] = self.reference_pdb
        else:
            pass
        # the models flag is a special case as well because it is either an int, a list
        # of ints, a list of strings, or a string
        if type(self.models) == int:  # convert to string
            self.flags["--models"] = str(self.models)
        elif type(self.models) == list:  # check if list of ints
            if type(self.models[0]) == int:  # convert to string
                self.flags["--models"] = " ".join(str(x) for x in self.models)
            elif type(self.models[0]) == str:  # join with space
                self.flags["--models"] = " ".join(self.models)
            else:
                raise TypeError(
                    "The models param must be either a list of ints/strings or a single int/string."
                )
        elif type(self.models) == str:  # probably good to go
            self.flags["--models"] = self.models
        else:
            raise TypeError(
                "The models param must be either a list of ints/strings or a single int/string."
            )
        self.flags.update(
            {
                "--max_recycles": str(self.max_recycles),
                "--recycle_tol": str(self.recycle_tol),
                "--type": self.model_type,
            }
        )
        # 19 total flags plus input_files
        self.allowed_flags = [
            # flags that have default values
            "--mock_msa_depth",
            "--nstruct",
            "--num_ensemble",
            "--pct_seq_mask",
            "--seed_start",
            "--version",
            # flags that are set by the constructor
            "--amber_relax",
            "--initial_guess",
            "--max_recycles",
            "--models",
            "--out_dir",
            "--recycle_tol",
            "--reference_pdb",
            "--type",
            # flags that are optional
            "--enable_dropout",
            "--simple_rmsd",
            "--output_pae",
            "--overwrite",
            "--save_intermediates",
            "--show_images",
        ]
        # use git to find the root of the repo
        repo = git.Repo(str(Path(__file__).resolve()), search_parent_directories=True)
        root = repo.git.rev_parse("--show-toplevel")
        self.python = str(Path(root) / "envs" / "crispy" / "bin" / "python")
        if os.path.exists(self.python):
            pass
        else:  # crispy env must be installed in envs/crispy or must be used on DIGS
            self.python = "/projects/crispy_shifty/envs/crispy/bin/python"
        self.script = str(
            Path(__file__).parent.parent.parent / "superfold" / "run_superfold.py"
        )
        self.tmpdir = None  # this will be updated by the setup_tmpdir method.
        self.command = None  # this will be updated by the setup_runner method.
        self.is_setup = False  # this will be updated by the setup_runner method.

    def get_command(self) -> str:
        """
        :return: command to run.
        """
        return self.command

    def get_fasta_path(self) -> str:
        """
        :return: fasta path.
        """
        return self.fasta_path

    def get_flags(self) -> Dict[str, str]:
        """
        :return: dictionary of flags.
        """
        return self.flags

    def get_script(self) -> str:
        """
        :return: script path.
        """
        return self.script

    def get_tmpdir(self) -> str:
        """
        :return: temporary directory path.
        """
        return self.tmpdir

    def override_input_file(self, input_file: str) -> None:
        """
        Override the input_file attribute.
        :param: input_file: The new input_file.
        :return: None
        """
        self.input_file = input_file
        return None

    def set_fasta_path(self, fasta_path: str) -> None:
        """
        :param: fasta_path: The path to the fasta file.
        :return: None.
        """
        self.fasta_path = fasta_path
        return None

    def set_script(self, script: str) -> None:
        """
        :param: script: The path to the script.
        :return: None.
        """
        self.script = script
        self.update_command()
        return 

    def setup_tmpdir(self) -> None:
        """
        :return: None
        Create a temporary directory for the SuperfoldRunner. Checks for various best
        practice locations for the tmpdir in the following order: TMPDIR, PSCRATCH,
        CSCRATCH, /net/scratch. Uses the cwd if none of these are available.
        """
        import os, pwd, uuid

        if os.environ.get("TMPDIR") is not None:
            tmpdir_root = os.environ.get("TMPDIR")
        elif os.environ.get("PSCRATCH") is not None:
            tmpdir_root = os.environ.get("PSCRATCH")
        elif os.environ.get("CSCRATCH") is not None:
            tmpdir_root = os.environ.get("CSCRATCH")
        elif os.path.exists("/net/scratch"):
            tmpdir_root = f"/net/scratch/{pwd.getpwuid(os.getuid()).pw_name}"
        else:
            tmpdir_root = os.getcwd()

        self.tmpdir = os.path.join(tmpdir_root, uuid.uuid4().hex)
        os.makedirs(self.tmpdir, exist_ok=True)
        return

    def teardown_tmpdir(self) -> None:
        """
        :return: None
        Remove the temporary directory for the SuperfoldRunner.
        """
        import shutil

        if self.tmpdir is not None:
            shutil.rmtree(self.tmpdir)
        return

    def update_command(self) -> None:
        """
        :return: None
        Update the command to run.
        """
        self.command = " ".join(
            [
                f"{self.python} {self.script}",
                f"{self.input_file}",
                " ".join([f"{k} {v}" for k, v in self.flags.items()]),
            ]
        )

    def update_flags(self, update_dict: Dict[str, str]) -> None:
        """
        :param: update_dict: dictionary of flags to update.
        :return: None
        Update the flags dictionary with the provided dictionary.
        Validate the flags before updating.
        """

        for flag in update_dict.keys():
            if flag not in self.allowed_flags:
                raise ValueError(
                    f"Flag {flag} is not allowed. Allowed flags are {self.allowed_flags}"
                )
        self.flags.update(update_dict)
        return

    def setup_runner(
        self, file: Optional[str] = None, flag_update: Optional[Dict[str, str]] = None
    ) -> None:
        """
        :param: file: path to input file. If None, use the dumped tmp.pdb.
        :param: flag_update: dictionary of flags to update, if any.
        :return: None
        Setup the SuperfoldRunner.
        Create a temporary directory for the SuperfoldRunner.
        Dump the pose temporarily to a PDB file in the temporary directory.
        Update the flags dictionary with the provided dictionary if any.
        Setup the command line arguments for the SuperfoldRunner.
        """
        import json, os, sys
        import pyrosetta.distributed.io as io

        # setup the tmpdir
        self.setup_tmpdir()
        out_path = self.tmpdir
        # set input_file
        if file is not None:
            self.input_file = file
        else:
            self.input_file = os.path.join(out_path, "tmp.pdb")
        # write the pose to a clean PDB file of only ATOM coordinates.
        tmp_pdb_path = os.path.join(out_path, "tmp.pdb")
        pdbstring = io.to_pdbstring(self.pose)
        with open(tmp_pdb_path, "w") as f:
            f.write(pdbstring)
        # update the flags with the path to the tmpdir
        self.update_flags({"--out_dir": out_path})
        if flag_update is not None:
            self.update_flags(flag_update)
        else:
            pass
        self.update_command()
        self.is_setup = True
        return

    def apply(self, pose: Pose) -> None:
        """
        :param: pose: Pose object to run Superfold on.
        :return: None
        Run Superfold on the provided pose in a subprocess.
        Read the results from the temporary directory and store them in the pose.
        Remove the temporary directory.
        """
        import json, os, sys
        from collections import defaultdict
        from glob import glob
        from pathlib import Path
        import pyrosetta
        from pyrosetta.rosetta.core.pose import setPoseExtraScore
        import pyrosetta.distributed.io as io

        # insert the root of the repo into the sys.path
        sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
        from crispy_shifty.protocols.mpnn import fasta_to_dict
        from crispy_shifty.utils.io import cmd

        assert self.is_setup, "SuperfoldRunner is not setup."

        scores = dict(pose.scores)
        # run the command in a subprocess
        out_err = cmd(self.command)
        print(out_err)
        json_files = glob(os.path.join(self.tmpdir, "*_prediction_results.json"))
        # read the json files and update a dict of dicts of dicts of scores
        # the outer dict is keyed by the pymol_name, values are all model/seed results
        # the inner dict is keyed by the model + seed, and the value is the scores dict
        results = defaultdict(dict)
        for json_file in json_files:
            pymol_name, model_seed, result = process_results_json(json_file)
            if self.load_decoys:
                if self.amber_relax:
                    suffix = "_relaxed.pdb"
                else:
                    suffix = "_unrelaxed.pdb"
                decoy_path = json_file.replace("_prediction_results.json", suffix)
                # load pose and turn it into a pdb string
                decoy_pdbstring = io.to_pdbstring(io.pose_from_file(decoy_path))
                result["decoy_pdbstring"] = decoy_pdbstring
            else:
                pass
            results[pymol_name].update({model_seed: result})
        # turn results back into a regular dict
        results = dict(results)
        # check if there were already sequences in the pose datacache
        seqs = {k: {"seq": v} for k, v in scores.items() if k in results.keys()}
        # check if a fasta was provided
        if self.fasta_path is not None:
            # check if the fasta is the same as the input file
            if self.fasta_path == self.input_file:
                # if so, make a dict of the sequences in the fasta
                tag_seq_dict = fasta_to_dict(self.fasta_path)
                # and nest the sequences in that dict
                tag_seq_dict = {k: {"seq": v} for k, v in tag_seq_dict.items()}
            else:
                raise NotImplementedError(
                    "Fasta path is not the same as the input file."
                )

            if len(seqs) > 0:  # check that the seqs dict matches the fasta dict
                if seqs == tag_seq_dict:
                    pass
                else:
                    seqs = tag_seq_dict  # we want the seqs we did predictions on
            else:
                seqs = tag_seq_dict  # we want the seqs we did predictions on

        elif len(seqs) == 0 and len(results) == 1:
            # then this was a single sequence run
            seqs = {"tmp": {"seq": pose.sequence()}}

        else:
            raise NotImplementedError("I am not sure how this behaves with silents")

        # update the results with the sequences and update the pose with those results
        for tag, result in results.items():
            result.update(seqs[tag])
            setPoseExtraScore(pose, tag, json.dumps(result))
        # clean up the temporary files
        self.teardown_tmpdir()
        return


class SuperfoldMultiPDB(SuperfoldRunner):
    """
    SuperfoldRunner for multiple PDB files.
    """

    import os, pwd, uuid, shutil
    import pyrosetta.distributed.io as io

    def __init__(
        self,
        *args,
        **kwargs,
    ):
        """
        :param: args: arguments to SuperfoldRunner.
        :param: kwargs: keyword arguments to SuperfoldRunner.
        :return: None
        Initialize the the base class for Superfold runners with common attributes.
        """

        from pyrosetta.rosetta.core.pose import Pose

        dummy_pose = Pose()
        # pass a dummy pose to the superclass

        super().__init__(*args, pose=dummy_pose, **kwargs)
        self.tag_pose_dict = {}

    def setup_runner(
        self,
        chains_to_keep: Optional[List[int]] = None,
        flag_update: Optional[Dict[str, str]] = None,
    ) -> None:
        """
        :param: chains_to_keep: list of chains to keep in the pose. If None, keep all
        chains. Must be a list of ints.
        :param: flag_update: dictionary of flags to update, if any.
        :return: None
        Setup the SuperfoldMultiPDB.
        Create a temporary directory for the SuperfoldMultiPDB.
        Make a dict of the poses and their tags.
        Dump the poses temporarily to PDB files in the temporary directory.
        Dump the pose temporarily to a PDB file in the temporary directory.
        Update the flags dictionary with the provided dictionary if any.
        Setup the command line arguments for the SuperfoldRunner.
        """
        import json, os, sys
        from glob import glob
        from pathlib import Path
        import pyrosetta
        import pyrosetta.distributed.io as io

        # insert the root of the repo into the sys.path
        sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
        from crispy_shifty.protocols.cleaning import path_to_pose_or_ppose

        # setup the tmpdir
        self.setup_tmpdir()
        # check that input_file was provided
        if self.input_file is None:
            raise ValueError("No input file provided.")
        else:
            pass
        # read in the input files as poses and store them in a dict
        for path in self.input_file.split():
            # the following is a bit unsafe to get rid of the extension
            # TODO use pathlib
            tag = os.path.basename(path).split(".pdb")[0]
            self.tag_pose_dict[tag] = next(
                path_to_pose_or_ppose(path=path, cluster_scores=True, pack_result=False)
            )
        # write the poses to clean PDB files of only ATOM coordinates.
        for tag, pose in self.tag_pose_dict.items():
            tmp_pdb_path = os.path.join(self.tmpdir, f"{tag}.pdb")
            if chains_to_keep is not None:
                # get the chains to keep
                chains_list = list(pose.split_by_chain())
                new_pose = Pose()
                for i, chain in enumerate(chains_list, start=1):
                    if i in chains_to_keep:
                        pyrosetta.rosetta.core.pose.append_pose_to_pose(
                            new_pose, chain, new_chain=True
                        )
                    else:
                        pass
                pdbstring = io.to_pdbstring(new_pose)
            else:
                pdbstring = io.to_pdbstring(pose)
            with open(tmp_pdb_path, "w") as f:
                f.write(pdbstring)
        # get a list of the PDB files in the tmpdir
        pdb_files = glob(os.path.join(self.tmpdir, "*.pdb"))
        # update the input file to point to this list of PDB files
        self.input_file = " ".join(pdb_files)
        # update the flags with the path to the tmpdir
        self.update_flags({"--out_dir": self.tmpdir})
        if flag_update is not None:
            self.update_flags(flag_update)
        else:
            pass
        self.update_command()
        self.is_setup = True
        return

    def apply(self) -> None:
        """
        :return: None
        Run Superfold on the input files.
        Read the results from the temporary directory and store them in the poses.
        Remove the temporary directory.
        """
        import json, os, sys
        from collections import defaultdict
        from glob import glob
        from pathlib import Path
        import pyrosetta
        from pyrosetta.rosetta.core.pose import setPoseExtraScore
        import pyrosetta.distributed.io as io

        # insert the root of the repo into the sys.path
        sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
        from crispy_shifty.protocols.mpnn import fasta_to_dict
        from crispy_shifty.utils.io import cmd

        assert self.is_setup, "SuperfoldRunner is not setup."

        # run the command in a subprocess
        out_err = cmd(self.command)
        print(out_err)
        json_files = glob(os.path.join(self.tmpdir, "*_prediction_results.json"))
        # read the json files and update a dict of dicts of dicts of scores
        # the outer dict is keyed by the pymol_name, values are all model/seed results
        # the inner dict is keyed by the model and seed, and the value is the scores
        results = defaultdict(dict)
        for json_file in json_files:
            pymol_name, model_seed, result = process_results_json(json_file)
            if self.load_decoys:
                if self.amber_relax:
                    suffix = "_relaxed.pdb"
                else:
                    suffix = "_unrelaxed.pdb"
                decoy_path = json_file.replace("_prediction_results.json", suffix)
                # load pose and turn it into a pdb string
                decoy_pdbstring = io.to_pdbstring(io.pose_from_file(decoy_path))
                result["decoy_pdbstring"] = decoy_pdbstring
            else:
                pass
            results[pymol_name].update({model_seed: result})
        # turn results back into a regular dict
        results = dict(results)
        # now put the results in the poses
        for tag, pose in self.tag_pose_dict.items():
            # get the scores from the pose
            scores = dict(pose.scores)
            # get the results for this tag
            result = results[tag]
            # update the result with the sequence and update the pose with the results
            result.update({"seq": pose.sequence()})
            setPoseExtraScore(pose, tag, json.dumps(result))
        # clean up the temporary files
        self.teardown_tmpdir()
        return

    def get_tag_pose_dict(self) -> Dict[str, Pose]:
        """
        :return: dict of the poses and their tags
        """
        return self.tag_pose_dict


@requires_init
def fold_bound_state(
    packed_pose_in: Optional[PackedPose] = None, **kwargs
) -> Iterator[PackedPose]:
    """
    :param: packed_pose_in: a PackedPose object to fold with the superfold script.
    :param: kwargs: keyword arguments to be passed to the superfold script.
    :return: an iterator of PackedPose objects.
    """

    from operator import lt, gt
    from pathlib import Path
    import sys
    from time import time
    import pyrosetta
    import pyrosetta.distributed.io as io

    # insert the root of the repo into the sys.path
    sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
    from crispy_shifty.protocols.cleaning import path_to_pose_or_ppose
    from crispy_shifty.utils.io import cmd, print_timestamp

    start_time = time()
    # hacky split pdb_path into pdb_path and fasta_path
    pdb_path = kwargs.pop("pdb_path")
    pdb_path, fasta_path = tuple(pdb_path.split("____"))

    # generate poses or convert input packed pose into pose
    if packed_pose_in is not None:
        poses = [io.to_pose(packed_pose_in)]
        pdb_path = "none"
    else:
        # skip the kwargs check
        poses = path_to_pose_or_ppose(
            path=pdb_path, cluster_scores=True, pack_result=False
        )

    for pose in poses:
        pose.update_residue_neighbors()
        scores = dict(pose.scores)
        print_timestamp("Setting up for AF2", start_time)
        runner = SuperfoldRunner(pose=pose, fasta_path=fasta_path, **kwargs)
        runner.setup_runner(file=fasta_path)
        # initial_guess, reference_pdb both are the tmp.pdb
        initial_guess = str(Path(runner.get_tmpdir()) / "tmp.pdb")
        reference_pdb = initial_guess
        flag_update = {
            "--initial_guess": initial_guess,
            "--reference_pdb": reference_pdb,
        }
        runner.update_flags(flag_update)
        runner.update_command()
        print_timestamp("Running AF2", start_time)
        runner.apply(pose)
        print_timestamp("AF2 complete, updating pose datacache", start_time)
        # update the scores dict
        scores.update(pose.scores)
        # update the pose with the updated scores dict
        for key, value in scores.items():
            pyrosetta.rosetta.core.pose.setPoseExtraScore(pose, key, value)
        # setup prefix, rank_on, filter_dict (in this case we can't get from kwargs)
        filter_dict = {
            "mean_plddt": (gt, 92.0),
            "rmsd_to_reference": (lt, 1.5),
            "mean_pae_interaction": (lt, 5),
        }
        rank_on = "mean_plddt"
        prefix = "mpnn_seq"
        for decoy in generate_decoys_from_pose(
            pose,
            filter_dict=filter_dict,
            label_first=True,
            prefix=prefix,
            rank_on=rank_on,
        ):
            packed_decoy = io.to_packed(decoy)
            yield packed_decoy


@requires_init
def fold_paired_state_Y(
    packed_pose_in: Optional[PackedPose] = None, **kwargs
) -> Iterator[PackedPose]:
    """
    :param: packed_pose_in: a PackedPose object to fold with the superfold script.
    :param: kwargs: keyword arguments to be passed to the superfold script.
    :return: an iterator of PackedPose objects.
    """

    from operator import lt, gt
    from pathlib import Path
    import sys
    from time import time
    import pyrosetta
    import pyrosetta.distributed.io as io
    from pyrosetta.rosetta.core.pose import Pose

    # insert the root of the repo into the sys.path
    sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
    from crispy_shifty.protocols.cleaning import path_to_pose_or_ppose
    from crispy_shifty.protocols.mpnn import dict_to_fasta, fasta_to_dict
    from crispy_shifty.utils.io import cmd, print_timestamp

    start_time = time()
    # hacky split pdb_path into pdb_path and fasta_path
    pdb_path = kwargs.pop("pdb_path")
    pdb_path, fasta_path = tuple(pdb_path.split("____"))

    # generate poses or convert input packed pose into pose
    if packed_pose_in is not None:
        poses = [io.to_pose(packed_pose_in)]
        pdb_path = "none"
    else:
        # skip the kwargs check
        poses = path_to_pose_or_ppose(
            path=pdb_path, cluster_scores=True, pack_result=False
        )

    for pose in poses:
        pose.update_residue_neighbors()
        scores = dict(pose.scores)
        # load fasta into a dict
        tmp_fasta_dict = fasta_to_dict(fasta_path)
        pose_chains = list(pose.split_by_chain())
        # slice out the bound state, aka chains A and B
        tmp_pose, X_pose = Pose(), Pose()
        pyrosetta.rosetta.core.pose.append_pose_to_pose(
            tmp_pose, pose_chains[0], new_chain=True
        )
        pyrosetta.rosetta.core.pose.append_pose_to_pose(
            tmp_pose, pose_chains[1], new_chain=True
        )
        # slice out the free state, aka chain C
        pyrosetta.rosetta.core.pose.append_pose_to_pose(
            X_pose, pose_chains[2], new_chain=True
        )
        # fix the fasta by splitting on chainbreaks '/' and rejoining the first two
        tmp_fasta_dict = {
            tag: "/".join(seq.split("/")[0:2]) for tag, seq in tmp_fasta_dict.items()
        }
        # change the pose to the modified pose
        pose = tmp_pose.clone()
        print_timestamp("Setting up for AF2", start_time)
        runner = SuperfoldRunner(
            pose=pose, fasta_path=fasta_path, load_decoys=True, **kwargs
        )
        runner.setup_runner(file=fasta_path)
        # initial_guess, reference_pdb both are the tmp.pdb
        initial_guess = str(Path(runner.get_tmpdir()) / "tmp.pdb")
        reference_pdb = initial_guess
        flag_update = {
            "--initial_guess": initial_guess,
            "--reference_pdb": reference_pdb,
        }
        # now we have to point to the right fasta file
        new_fasta_path = str(Path(runner.get_tmpdir()) / "tmp.fa")
        dict_to_fasta(tmp_fasta_dict, new_fasta_path)
        runner.set_fasta_path(new_fasta_path)
        runner.override_input_file(new_fasta_path)
        runner.update_flags(flag_update)
        runner.update_command()
        print_timestamp("Running AF2", start_time)
        runner.apply(pose)
        print_timestamp("AF2 complete, updating pose datacache", start_time)
        # update the scores dict
        scores.update(pose.scores)
        # update the pose with the updated scores dict
        for key, value in scores.items():
            pyrosetta.rosetta.core.pose.setPoseExtraScore(pose, key, value)
        # setup prefix, rank_on, filter_dict (in this case we can't get from kwargs)
        filter_dict = {
            "mean_plddt": (gt, 92.0),
            "rmsd_to_reference": (lt, 1.5),
            "mean_pae_interaction": (lt, 5),
        }
        rank_on = "mean_plddt"
        prefix = "mpnn_seq"
        print_timestamp("Generating decoys", start_time)
        for decoy in generate_decoys_from_pose(
            pose,
            filter_dict=filter_dict,
            generate_prediction_decoys=True,
            label_first=True,
            prefix=prefix,
            rank_on=rank_on,
        ):
            # add the free state back into the decoy
            pyrosetta.rosetta.core.pose.append_pose_to_pose(
                decoy, X_pose, new_chain=True
            )
            # get the chA sequence
            chA_seq = list(decoy.split_by_chain())[0].sequence()
            # setup SimpleThreadingMover
            stm = pyrosetta.rosetta.protocols.simple_moves.SimpleThreadingMover()
            # thread the sequence from chA onto chA
            stm.set_sequence(chA_seq, start_position=decoy.chain_begin(3))
            stm.apply(decoy)
            # rename af2 metrics to have Y_ prefix 
            decoy_scores = dict(decoy.scores)
            for key, value in decoy_scores.items():
                if key in af2_metrics:
                    pyrosetta.rosetta.core.pose.setPoseExtraScore(
                        decoy, f"Y_{key}", value
                    )

            packed_decoy = io.to_packed(decoy)
            yield packed_decoy


@requires_init
def fold_paired_state_X(
    packed_pose_in: Optional[PackedPose] = None, **kwargs
) -> Iterator[PackedPose]:
    """
    :param: packed_pose_in: a PackedPose object to fold with the Superfold script.
    :param: kwargs: keyword arguments to be passed to the Superfold script.
    :return: an iterator of PackedPose objects.
    """

    from pathlib import Path
    import os, sys
    from time import time
    import pyrosetta
    import pyrosetta.distributed.io as io
    from pyrosetta.rosetta.core.pose import Pose

    # insert the root of the repo into the sys.path
    sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
    from crispy_shifty.protocols.cleaning import path_to_pose_or_ppose
    from crispy_shifty.protocols.mpnn import dict_to_fasta, fasta_to_dict
    from crispy_shifty.utils.io import cmd, print_timestamp

    start_time = time()
    # get the pdb_path from the kwargs
    pdb_path = kwargs.pop("pdb_path")
    # there are multiple paths in the pdb_path, we need to split them and rejoin them
    pdb_paths = pdb_path.split("____")
    pdb_path = " ".join(pdb_paths)

    # this function is special, we don't want a packed_pose_in ever, we maintain it as
    # a kwarg for backward compatibility with PyRosettaCluster
    if packed_pose_in is not None:
        raise ValueError("This function is not intended to have a packed_pose_in")
    else:
        pass

    print_timestamp("Setting up for AF2", start_time)
    runner = SuperfoldMultiPDB(input_file=pdb_path, load_decoys=True, **kwargs)
    runner.setup_runner(chains_to_keep=[3])
    print_timestamp("Running AF2", start_time)
    runner.apply()
    print_timestamp("AF2 complete, updating pose datacache", start_time)
    # get the updated poses from the runner
    tag_pose_dict = runner.get_tag_pose_dict()
    # filter the decoys
    filter_dict = {
        "mean_plddt": (gt, 92.0),
        "rmsd_to_reference": (lt, 1.5),
    }
    rank_on = "mean_plddt"
    print_timestamp("Generating decoys", start_time)
    sw = pyrosetta.rosetta.protocols.simple_moves.SwitchChainOrderMover()
    sw.chain_order("123")
    for tag, pose in tag_pose_dict.items():
        for decoy in generate_decoys_from_pose(
            pose,
            filter_dict=filter_dict,
            generate_prediction_decoys=True,
            label_first=False,
            prefix=tag,
            rank_on=rank_on,
        ):
            scores = dict(decoy.scores)
            bound_pose = None
            for original_path in pdb_paths:
                if tag in original_path:
                    bound_pose = next(
                        path_to_pose_or_ppose(
                            path=original_path, cluster_scores=True, pack_result=False
                        )
                    )
                    final_pose = Pose()
                    # get the first two chains from the input
                    for chain in list(bound_pose.split_by_chain())[:2]:
                        pyrosetta.rosetta.core.pose.append_pose_to_pose(
                            final_pose, chain, new_chain=True
                        )
                    pyrosetta.rosetta.core.pose.append_pose_to_pose(
                        final_pose, decoy, new_chain=True
                    )
                    sw.apply(final_pose)
                    break
                else:
                    continue
            if bound_pose is None:
                raise RuntimeError
            else: 
                pass
            for key, value in scores.items():
                pyrosetta.rosetta.core.pose.setPoseExtraScore(final_pose, key, value)
            final_ppose = io.to_packed(final_pose)
            yield final_ppose


@requires_init
def fold_dimer_Y(
    packed_pose_in: Optional[PackedPose] = None, **kwargs
) -> Iterator[PackedPose]:
    """
    :param: packed_pose_in: a PackedPose object to fold with the superfold script.
    :param: kwargs: keyword arguments to be passed to the superfold script.
    :return: an iterator of PackedPose objects.
    """

    from operator import lt, gt
    from pathlib import Path
    import sys
    from time import time
    import pyrosetta
    import pyrosetta.distributed.io as io
    from pyrosetta.rosetta.core.pose import Pose

    # insert the root of the repo into the sys.path
    sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
    from crispy_shifty.protocols.cleaning import path_to_pose_or_ppose
    from crispy_shifty.protocols.mpnn import dict_to_fasta, fasta_to_dict
    from crispy_shifty.utils.io import cmd, print_timestamp

    start_time = time()
    # hacky split pdb_path into pdb_path and fasta_path
    pdb_path = kwargs.pop("pdb_path")
    pdb_path, fasta_path = tuple(pdb_path.split("____"))

    # generate poses or convert input packed pose into pose
    if packed_pose_in is not None:
        poses = [io.to_pose(packed_pose_in)]
        pdb_path = "none"
    else:
        # skip the kwargs check
        poses = path_to_pose_or_ppose(
            path=pdb_path, cluster_scores=True, pack_result=False
        )

    for pose in poses:
        pose.update_residue_neighbors()
        scores = dict(pose.scores)
        # load fasta into a dict
        tmp_fasta_dict = fasta_to_dict(fasta_path)
        pose_chains = list(pose.split_by_chain())
        Y_pose = Pose()
        # free state is chains A and B
        # slice out the bound state, aka the last two chains
        pyrosetta.rosetta.core.pose.append_pose_to_pose(
            Y_pose, pose_chains[-2], new_chain=True
        )
        pyrosetta.rosetta.core.pose.append_pose_to_pose(
            Y_pose, pose_chains[-1], new_chain=True
        )
        # fix the fasta by splitting on chainbreaks '/' and rejoining the last two
        tmp_fasta_dict = {
            tag: "/".join(seq.split("/")[-2:]) for tag, seq in tmp_fasta_dict.items()
        }
        # change the pose to the modified pose
        pose = Y_pose.clone()
        print_timestamp("Setting up for AF2", start_time)
        runner = SuperfoldRunner(
            pose=pose, fasta_path=fasta_path, load_decoys=True, simple_rmsd=True, **kwargs
        )
        runner.setup_runner(file=fasta_path)
        # initial_guess, reference_pdb both are the tmp.pdb
        initial_guess = str(Path(runner.get_tmpdir()) / "tmp.pdb")
        reference_pdb = initial_guess
        flag_update = {
            "--initial_guess": initial_guess,
            "--reference_pdb": reference_pdb,
        }
        # now we have to point to the right fasta file
        new_fasta_path = str(Path(runner.get_tmpdir()) / "tmp.fa")
        dict_to_fasta(tmp_fasta_dict, new_fasta_path)
        runner.set_fasta_path(new_fasta_path)
        runner.override_input_file(new_fasta_path)
        runner.update_flags(flag_update)
        # runner.set_script(runner.script.replace("_devel", "")) # TODO for RMSD bug
        runner.update_command()
        print_timestamp("Running AF2", start_time)
        runner.apply(pose)
        print_timestamp("AF2 complete, updating pose datacache", start_time)
        # update the scores dict
        scores.update(pose.scores)
        # update the pose with the updated scores dict
        for key, value in scores.items():
            pyrosetta.rosetta.core.pose.setPoseExtraScore(pose, key, value)
        # setup prefix, rank_on, filter_dict (in this case we can't get from kwargs)
        # TODO, for the pilot run i will not filter the decoys
        filter_dict = {}
        # filter_dict = {
        #     "mean_plddt": (gt, 90.0),
        #     "rmsd_to_reference": (lt, 1.75),
        #     "mean_pae_interaction": (lt, 7.5),
        # }
        # rank_on = "mean_plddt"
        prefix = "mpnn_seq"
        print_timestamp("Generating decoys", start_time)
        for tmp_decoy in generate_decoys_from_pose(
            pose,
            filter_dict=filter_dict,
            generate_prediction_decoys=True,
            label_first=True,
            prefix=prefix,
            rank_on=False,
        ):
            # add the free state back into the decoy
            decoy = Pose()
            tmp_decoy_split = list(tmp_decoy.split_by_chain())
            pyrosetta.rosetta.core.pose.append_pose_to_pose(
                decoy, pose_chains[0], new_chain=True
            )
            pyrosetta.rosetta.core.pose.append_pose_to_pose(
                decoy, pose_chains[1], new_chain=True
            )
            pyrosetta.rosetta.core.pose.append_pose_to_pose(
                decoy, tmp_decoy_split[0], new_chain=True
            )
            pyrosetta.rosetta.core.pose.append_pose_to_pose(
                decoy, tmp_decoy_split[1], new_chain=True
            )
            # get the state Y sequence
            new_seq = tmp_decoy.sequence()
            # setup SimpleThreadingMover
            stm = pyrosetta.rosetta.protocols.simple_moves.SimpleThreadingMover()
            # thread the sequence from state Y onto state X
            stm.set_sequence(new_seq, start_position=decoy.chain_begin(1))
            stm.apply(decoy)
            decoy_scores = dict(tmp_decoy.scores)
            for key, value in decoy_scores.items():
                # rename af2 metrics to have Y_ prefix 
                if key in af2_metrics:
                    pyrosetta.rosetta.core.pose.setPoseExtraScore(
                        decoy, f"Y_{key}", value
                    )
                else:
                    pyrosetta.rosetta.core.pose.setPoseExtraScore(
                        decoy, key, value
                    )

            packed_decoy = io.to_packed(decoy)
            yield packed_decoy


@requires_init
def fold_dimer_X(
    packed_pose_in: Optional[PackedPose] = None, **kwargs
) -> Iterator[PackedPose]:
    """
    :param: packed_pose_in: a PackedPose object to fold with the Superfold script.
    :param: kwargs: keyword arguments to be passed to the Superfold script.
    :return: an iterator of PackedPose objects.
    """

    from pathlib import Path
    import sys
    from time import time
    import pyrosetta
    import pyrosetta.distributed.io as io

    # insert the root of the repo into the sys.path
    sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
    from crispy_shifty.protocols.cleaning import path_to_pose_or_ppose
    from crispy_shifty.utils.io import print_timestamp

    start_time = time()
    # get the pdb_path from the kwargs
    pdb_path = kwargs.pop("pdb_path")

    # generate poses or convert input packed pose into pose
    if packed_pose_in is not None:
        poses = [io.to_pose(packed_pose_in)]
        pdb_path = "none"
    else:
        # skip the kwargs check
        poses = path_to_pose_or_ppose(
            path=pdb_path, cluster_scores=True, pack_result=False
        )
        
    for pose in poses:
        pose.update_residue_neighbors()
        scores = dict(pose.scores)
        
        X_pose_1, X_pose_2, _, _ = pose.split_by_chain()
        for X_pose, protomer in zip([X_pose_1, X_pose_2], ['A', 'B']):
            # change the pose to the modified pose
            pose = X_pose.clone()
            print_timestamp("Setting up for AF2", start_time)
            runner = SuperfoldRunner(
                pose=pose, load_decoys=True, simple_rmsd=True, initial_guess=True, **kwargs
            )
            runner.setup_runner()
            runner.update_command()
            print_timestamp("Running AF2", start_time)
            runner.apply(pose)
            print_timestamp("AF2 complete, updating pose datacache", start_time)
            # update the scores dict
            scores.update(pose.scores)
            scores['X_protomer'] = protomer
            # update the pose with the updated scores dict
            for key, value in scores.items():
                pyrosetta.rosetta.core.pose.setPoseExtraScore(pose, key, value)
            # setup prefix, rank_on, filter_dict (in this case we can't get from kwargs)
            # TODO, for the pilot run i will not filter the decoys
            filter_dict = {}
            # filter_dict = {
            #     "mean_plddt": (gt, 90.0),
            #     "rmsd_to_reference": (lt, 1.75),
            #     "mean_pae_interaction": (lt, 7.5),
            # }
            # rank_on = "mean_plddt"
            print_timestamp("Generating decoys", start_time)
            for decoy in generate_decoys_from_pose(
                pose,
                filter_dict=filter_dict,
                generate_prediction_decoys=True,
                label_first=True,
                prefix='tmp',
                rank_on=False,
            ):
                decoy_scores = dict(decoy.scores)
                for key, value in decoy_scores.items():
                    # rename af2 metrics to have X_ prefix 
                    if key in af2_metrics:
                        pyrosetta.rosetta.core.pose.setPoseExtraScore(
                            decoy, f"X_{key}", value
                        )
                    else:
                        pyrosetta.rosetta.core.pose.setPoseExtraScore(
                            decoy, key, value
                        )

                packed_decoy = io.to_packed(decoy)
                yield packed_decoy
