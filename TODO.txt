remember to maintain the envs and repos on perlmutter and janelia clusters
how to do better than last round, chA:
    - bicistronic screen had high false positives, possibly co-expressed genes resulted in "locked" state Y complexes.
    - longer loops for state Ys, force state X to have longer (63 and 74-7 have longer than parent, 129 only has match)
    - torsional space only for backbone generation, later relax into predictions (in torsional space?)
    - absolutely no disulfides during design >:(
    - don't over optimize on SAP

how to do better than last round, chB:
    - longer chB, all have 27 except 63 which had 21 (as opposed to 17-25)
    - charges? + C term, - N term
    -     check results of the chB order4
    - FF129 has a very polar interface, Cterm sequence is QLQKKNKKQQK
    - Some have lower helical propensity and most lower coiled-coil propensity at termini (did not quantify)
    - backside hydrophobics and aromatics may break coiled coil propensity, resurfacing to all polars sometimes seemed to cause issues (also sometimes fixed issues like in FF75) 
    -     check results of the chB order4

Strategy:
Use MPNN for sequence design after smaller sampling runs with Rosetta to sample backbones
Probably only need delta SAP and CMS/ddG/SASA for interface filtering
Start MSD sampling from designs that alphafold to single state state Y
Use MPNN for two-state sequence design after smaller sampling runs with “almost linkres” to sample backbones again
Look for complex prediction on AF2 then fold state X
Increase SAP tolerance somewhat
If disulfide stapled states are needed or wanted, just staple and predict

Pipeline:
make bound states ~180k

loop, allow extension, mpnn
order chA and do SEC / expression screening 
order chB and do SEC / expression screening too?

dev TODOs:
    - finalize env.yml (pip install typing-extensions==3.10.0.2) and build envs on digs, perlmutter, and janelia
    - add crispy kernel to ipython kernelspecs on perlmutter and janelia
    - test python interpreter finding with git root on perlmutter and janelia
    - run_superfold_devel.py needs to work with turbo, initial guess, fasta and reference pdb all at once
    - test with single pdb no fasta, pdb+fasta, and ...? TODO
    - test gen_array_tasks with perlmutter mode, GPU mode, and CPU mode
    - Use if elif elif else tmpdir construction for mpnn? 
    - gen_parallel_array_tasks? I think all it would need to do would be to change the .sh file to use GNU parallel (need to add GPU support anyway)
    - test PAE summarization in fasta mode
    - test neighborhood vs difference only MSD with both "almost linkres" and tMPNN

    - Example notebooks for MPNN and superfold in crispy_shifty/examples


TODO: 
    00 filter scaffold sets # check lengths of non-junctions to make sure there's nothing above 240? 220? # run
    01 prep inputs # run
    02 make states # change to array tasks? # run
    00 design bound states # probably split into junctions x 1-3, non-junctions x 5-10 # run
    01 loop bound_states # test 0-1,2,3 adjustment per side comparison # run
    02 MPNN bound states # test how many fold in the next step # run
    03 fold bound states # get working on perlmutter # turn off initial guess if not needed # run
    04 loop parents # lookup in free state df for common pdb parent, state 0? then use remodel only design around loop # run
    05 design paired states # almost linkres in msd.py # run
    06 MPNN paired states # make MPNN msd # run
    07 fold paired states # reuse folding.py Y first then X. # run
    08 detail and filter # staple? peptide resurf? refold? probably mostly rosetta filters # run
    09 order and analyze


Paper TODOs:
What will fig. 4 be:
FRET? NMR? photoswitching? negative cooperativity? 
crowdsource cool tricks, maybe ask some synbio people

crispy snippy TODOs:
fluo polarization for protease or fluorophore/quencher?

